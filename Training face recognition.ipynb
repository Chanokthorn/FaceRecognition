{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.insert(0, \"/opt/intel/mkl/lib/intel64\")\n",
    "sys.path.insert(0, \"/usr/local/lib/python3.6/site-packages\")\n",
    "import dlib\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "\n",
    "def dlibFacelandmarkToNumpy(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    " \n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    " \n",
    "    return coords\n",
    " \n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "DATA_AMOUNT = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "\n",
    "STORE_LOCATION = 'C:\\\\Users\\\\Bone\\\\Desktop\\\\faces\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e562febbfae1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrect\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrects\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#         print('found')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlibFacelandmarkToNumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboundingRect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "videoInput = cv2.VideoCapture(0)\n",
    "data = np.ndarray((DATA_AMOUNT,68,2), dtype = float)\n",
    "data_count = 0\n",
    "\n",
    "while (data_count < DATA_AMOUNT):\n",
    "    \n",
    "    _,frame = videoInput.read()\n",
    "   \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    rects = detector(gray, 0)\n",
    "    for rect in rects:\n",
    "#         print('found')\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = dlibFacelandmarkToNumpy(shape)\n",
    "        x, y, w, h = cv2.boundingRect(shape)\n",
    "#         print(shape)\n",
    "#         print('x:',x, 'y:', y, 'w:', w,'h:', h)\n",
    "        shape[:,0] -= x\n",
    "        shape[:,1] -= y\n",
    "        shape_x = shape[:,0]\n",
    "        shape_y = shape[:,1]\n",
    "        shape = shape.astype(float)\n",
    "        shape[:,0] = np.divide(shape_x, w)\n",
    "        shape[:,1] = np.divide(shape_y, h)\n",
    "        data[data_count,:,:] = shape\n",
    "        print(int(data_count * 100 / DATA_AMOUNT),end = '\\r')\n",
    "#         print(shape)\n",
    "        data_count += 1\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "videoInput.release()\n",
    "# print(data)\n",
    "name = input(\"Enter name: \")\n",
    "pickle.dump(data,open(STORE_LOCATION + name, 'wb'))\n",
    "print('stored')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of people:5\n",
      "nameBone\n",
      "nameChal\n",
      "nameBook\n",
      "nameP'An\n",
      "nameP'Ton\n",
      "torch.Size([2000, 136])\n",
      "torch.Size([2000, 5])\n",
      "done loading data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def unpickle(file):\n",
    "    with open(file,'rb') as fo:\n",
    "        output = pickle.load(fo, encoding = 'ASCII')\n",
    "    return output\n",
    "n = int(input('amount of people:'))\n",
    "\n",
    "classes = list()\n",
    "\n",
    "TRAINING_AMOUNT = int(n * DATA_AMOUNT * 4 / 5)\n",
    "TEST_AMOUNT = int(n * DATA_AMOUNT * 1 / 5)\n",
    "\n",
    "training_data = np.ndarray((TRAINING_AMOUNT,68*2))\n",
    "training_labels = np.ndarray((TRAINING_AMOUNT,n))\n",
    "\n",
    "test_data = np.ndarray((TEST_AMOUNT,68 * 2))\n",
    "test_labels = np.ndarray((TEST_AMOUNT,n))\n",
    "\n",
    "training_counter = 0\n",
    "test_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range (n):\n",
    "    name = input('name')\n",
    "    classes.append(name)\n",
    "    data = unpickle(STORE_LOCATION + name)\n",
    "    \n",
    "#     print(data)\n",
    "    training_data[training_counter : training_counter + int(DATA_AMOUNT * 4 / 5),:] = data[: int(DATA_AMOUNT * 4 / 5), :, :].reshape(int(DATA_AMOUNT * 4 / 5), 68 * 2)\n",
    "    test_data[test_counter : test_counter + int(DATA_AMOUNT * 1 / 5)] = data[int(DATA_AMOUNT * 4 / 5) :, :, :].reshape(int(DATA_AMOUNT * 1 / 5), 68 * 2)\n",
    "   \n",
    "    training_labels[training_counter :, :] = 0\n",
    "    training_labels[training_counter : training_counter + int(DATA_AMOUNT * 4 / 5),i] = 1\n",
    "    test_labels[test_counter :, :] = 0\n",
    "    test_labels[test_counter : test_counter + int(DATA_AMOUNT * 1 / 5), i] = 1\n",
    "    \n",
    "    training_counter += int(DATA_AMOUNT * 4 / 5)\n",
    "    test_counter += int(DATA_AMOUNT * 1 / 5)\n",
    "training_data = torch.from_numpy(training_data)\n",
    "training_labels = torch.from_numpy(training_labels)\n",
    "# print(training_data[0])\n",
    "# print(training_labels[0])\n",
    "print(training_data.shape)\n",
    "print(training_labels.shape)\n",
    "\n",
    "print('done loading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of people:4\n",
      "nameBone\n",
      "nameChal\n",
      "nameTanawinBook\n",
      "namethipok\n",
      "torch.Size([1600, 136])\n",
      "torch.Size([1600, 1])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# def unpickle(file):\n",
    "#     with open(file,'rb') as fo:\n",
    "#         output = pickle.load(fo, encoding = 'ASCII')\n",
    "#     return output\n",
    "# n = int(input('amount of people:'))\n",
    "\n",
    "# classes = list()\n",
    "\n",
    "# TRAINING_AMOUNT = int(n * DATA_AMOUNT * 4 / 5)\n",
    "# TEST_AMOUNT = int(n * DATA_AMOUNT * 1 / 5)\n",
    "\n",
    "# training_data = np.ndarray((TRAINING_AMOUNT,68*2))\n",
    "# training_labels = np.ndarray((TRAINING_AMOUNT,1))\n",
    "\n",
    "# test_data = np.ndarray((TEST_AMOUNT,68 * 2))\n",
    "# test_labels = np.ndarray((TEST_AMOUNT,1))\n",
    "\n",
    "# training_counter = 0\n",
    "# test_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "# for i in range (n):\n",
    "#     name = input('name')\n",
    "#     classes.append(name)\n",
    "#     data = unpickle(STORE_LOCATION + name)\n",
    "    \n",
    "# #     print(data)\n",
    "#     training_data[training_counter : training_counter + int(DATA_AMOUNT * 4 / 5),:] = data[: int(DATA_AMOUNT * 4 / 5), :, :].reshape(int(DATA_AMOUNT * 4 / 5), 68 * 2)\n",
    "#     test_data[test_counter : test_counter + int(DATA_AMOUNT * 1 / 5)] = data[int(DATA_AMOUNT * 4 / 5) :, :, :].reshape(int(DATA_AMOUNT * 1 / 5), 68 * 2)\n",
    "   \n",
    "#     training_labels[training_counter : training_counter + int(DATA_AMOUNT * 4 / 5)] = i\n",
    "#     test_labels[test_counter : test_counter + int(DATA_AMOUNT * 1 / 5)] = i\n",
    "    \n",
    "#     training_counter += int(DATA_AMOUNT * 4 / 5)\n",
    "#     test_counter += int(DATA_AMOUNT * 1 / 5)\n",
    "# training_data = torch.from_numpy(training_data)\n",
    "# training_labels = torch.from_numpy(training_labels)\n",
    "# # print(training_data[0])\n",
    "# # print(training_labels[0])\n",
    "# print(training_data.shape)\n",
    "# print(training_labels.shape)\n",
    "\n",
    "# # print('done loading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[1199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class landmarksData(Dataset):\n",
    "    def __init__(self, data, labels, classes,transform=None, data_dir=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform=transform\n",
    "        self.classes = classes\n",
    "    def __getitem__(self,index):\n",
    "        single_landmark_labels = self.labels[index]\n",
    "        single_landmarks = self.data[index]\n",
    "        return (single_landmarks,single_landmark_labels)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "training_set = landmarksData(training_data, training_labels, classes)\n",
    "test_set = landmarksData(test_data, test_labels, classes)\n",
    "print(training_set.__len__())\n",
    "print(test_set.__len__())\n",
    "# print(training_set.__getitem__(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(training_data.type)\n",
    "# print(training_labels.type)\n",
    "# training_set = torch.utils.data.TensorDataset(training_data,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landmarks:  \n",
      " 0.0000\n",
      " 0.3130\n",
      " 0.0168\n",
      " 0.4431\n",
      " 0.0462\n",
      " 0.5650\n",
      " 0.0798\n",
      " 0.6870\n",
      " 0.1345\n",
      " 0.7967\n",
      " 0.2227\n",
      " 0.8862\n",
      " 0.3361\n",
      " 0.9512\n",
      " 0.4580\n",
      " 0.9919\n",
      " 0.5840\n",
      " 0.9959\n",
      " 0.7059\n",
      " 0.9675\n",
      " 0.8025\n",
      " 0.8943\n",
      " 0.8866\n",
      " 0.8049\n",
      " 0.9496\n",
      " 0.6992\n",
      " 0.9832\n",
      " 0.5813\n",
      " 0.9958\n",
      " 0.4553\n",
      " 0.9958\n",
      " 0.3252\n",
      " 0.9832\n",
      " 0.1951\n",
      " 0.0588\n",
      " 0.1951\n",
      " 0.1092\n",
      " 0.1098\n",
      " 0.2017\n",
      " 0.0650\n",
      " 0.3109\n",
      " 0.0610\n",
      " 0.4160\n",
      " 0.0894\n",
      " 0.5294\n",
      " 0.0691\n",
      " 0.6261\n",
      " 0.0244\n",
      " 0.7311\n",
      " 0.0000\n",
      " 0.8361\n",
      " 0.0163\n",
      " 0.9118\n",
      " 0.0854\n",
      " 0.4874\n",
      " 0.1992\n",
      " 0.4958\n",
      " 0.2805\n",
      " 0.5042\n",
      " 0.3618\n",
      " 0.5126\n",
      " 0.4472\n",
      " 0.3992\n",
      " 0.5407\n",
      " 0.4622\n",
      " 0.5407\n",
      " 0.5210\n",
      " 0.5447\n",
      " 0.5798\n",
      " 0.5325\n",
      " 0.6387\n",
      " 0.5203\n",
      " 0.1639\n",
      " 0.2683\n",
      " 0.2185\n",
      " 0.2398\n",
      " 0.2815\n",
      " 0.2317\n",
      " 0.3487\n",
      " 0.2561\n",
      " 0.2857\n",
      " 0.2683\n",
      " 0.2227\n",
      " 0.2724\n",
      " 0.6345\n",
      " 0.2236\n",
      " 0.6849\n",
      " 0.1870\n",
      " 0.7521\n",
      " 0.1829\n",
      " 0.8151\n",
      " 0.1951\n",
      " 0.7605\n",
      " 0.2154\n",
      " 0.6975\n",
      " 0.2236\n",
      " 0.3361\n",
      " 0.7439\n",
      " 0.3992\n",
      " 0.6829\n",
      " 0.4706\n",
      " 0.6423\n",
      " 0.5294\n",
      " 0.6504\n",
      " 0.5840\n",
      " 0.6301\n",
      " 0.6639\n",
      " 0.6585\n",
      " 0.7395\n",
      " 0.7073\n",
      " 0.6765\n",
      " 0.7805\n",
      " 0.6092\n",
      " 0.8171\n",
      " 0.5462\n",
      " 0.8293\n",
      " 0.4832\n",
      " 0.8293\n",
      " 0.4118\n",
      " 0.8049\n",
      " 0.3739\n",
      " 0.7398\n",
      " 0.4748\n",
      " 0.6951\n",
      " 0.5336\n",
      " 0.6951\n",
      " 0.5924\n",
      " 0.6870\n",
      " 0.7059\n",
      " 0.7114\n",
      " 0.5966\n",
      " 0.7439\n",
      " 0.5378\n",
      " 0.7520\n",
      " 0.4790\n",
      " 0.7480\n",
      "[torch.DoubleTensor of size 136]\n",
      "\n",
      "label:  \n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainloader = DataLoader(training_set, batch_size=4,shuffle=True)\n",
    "dataiter = iter(trainloader)\n",
    "landmarks, label = dataiter.next()\n",
    "print(\"landmarks: \",landmarks[0])\n",
    "print(\"label: \",label[0])\n",
    "testloader = DataLoader(test_set, batch_size=4,shuffle=True)\n",
    "testiter = iter(testloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "def foo(l, dtype=float):\n",
    "    return map(dtype, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (fc1): Linear (136 -> 136)\n",
      "  (fc2): Linear (136 -> 64)\n",
      "  (fc3): Linear (64 -> 5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(68 * 2, 68 * 2)\n",
    "        self.fc2 = nn.Linear(68 * 2, 64)\n",
    "        self.fc3 = nn.Linear(64, n)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "# net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion =  nn.MSELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:  Variable containing:\n",
      "1.00000e-02 *\n",
      " -0.0386  1.9010  5.6941  6.7038  3.0685\n",
      "  0.3567  1.5441  5.7465  7.0456  2.9810\n",
      "  0.3551  1.1564  5.8447  7.1089  3.3287\n",
      "  0.3838  1.3767  5.8212  7.0896  3.2119\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[1,   100] loss: 0.187\n",
      "[1,   200] loss: 0.186\n",
      "[1,   300] loss: 0.185\n",
      "[1,   400] loss: 0.185\n",
      "[1,   500] loss: 0.184\n",
      "outputs:  Variable containing:\n",
      "1.00000e-02 *\n",
      "  1.7352  2.0731  6.7017  8.2924  4.3827\n",
      "  1.6622  2.3206  6.6404  8.0705  4.0067\n",
      "  1.4405  2.6710  6.3677  8.1623  4.1760\n",
      "  1.8780  2.3211  7.0002  8.1625  3.9602\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[2,   100] loss: 0.183\n",
      "[2,   200] loss: 0.183\n",
      "[2,   300] loss: 0.181\n",
      "[2,   400] loss: 0.183\n",
      "[2,   500] loss: 0.181\n",
      "outputs:  Variable containing:\n",
      "1.00000e-02 *\n",
      "  2.8552  3.0782  7.4065  9.3539  5.4909\n",
      "  3.2303  3.2296  8.0828  9.4730  5.6094\n",
      "  2.9211  3.3110  7.5759  9.3758  5.4091\n",
      "  2.6506  3.3284  7.2439  8.8975  4.8779\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[3,   100] loss: 0.180\n",
      "[3,   200] loss: 0.179\n",
      "[3,   300] loss: 0.180\n",
      "[3,   400] loss: 0.179\n",
      "[3,   500] loss: 0.179\n",
      "outputs:  Variable containing:\n",
      " 0.0395  0.0416  0.0814  0.1024  0.0631\n",
      " 0.0342  0.0492  0.0774  0.0961  0.0614\n",
      " 0.0407  0.0426  0.0841  0.1011  0.0606\n",
      " 0.0404  0.0423  0.0847  0.1029  0.0647\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[4,   100] loss: 0.178\n",
      "[4,   200] loss: 0.178\n",
      "[4,   300] loss: 0.177\n",
      "[4,   400] loss: 0.176\n",
      "[4,   500] loss: 0.176\n",
      "outputs:  Variable containing:\n",
      " 0.0492  0.0514  0.0887  0.1099  0.0735\n",
      " 0.0492  0.0521  0.0876  0.1101  0.0732\n",
      " 0.0500  0.0527  0.0876  0.1116  0.0743\n",
      " 0.0424  0.0584  0.0788  0.1036  0.0712\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[5,   100] loss: 0.175\n",
      "[5,   200] loss: 0.175\n",
      "[5,   300] loss: 0.175\n",
      "[5,   400] loss: 0.174\n",
      "[5,   500] loss: 0.174\n",
      "outputs:  Variable containing:\n",
      " 0.0542  0.0668  0.0840  0.1138  0.0814\n",
      " 0.0547  0.0654  0.0827  0.1138  0.0802\n",
      " 0.0610  0.0595  0.0936  0.1207  0.0836\n",
      " 0.0580  0.0614  0.0936  0.1149  0.0783\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[6,   100] loss: 0.173\n",
      "[6,   200] loss: 0.173\n",
      "[6,   300] loss: 0.172\n",
      "[6,   400] loss: 0.172\n",
      "[6,   500] loss: 0.172\n",
      "outputs:  Variable containing:\n",
      " 0.0732  0.0717  0.1032  0.1287  0.0932\n",
      " 0.0679  0.0706  0.0983  0.1255  0.0925\n",
      " 0.0738  0.0721  0.1135  0.1292  0.1010\n",
      " 0.0640  0.0748  0.0931  0.1211  0.0908\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[7,   100] loss: 0.172\n",
      "[7,   200] loss: 0.172\n",
      "[7,   300] loss: 0.171\n",
      "[7,   400] loss: 0.170\n",
      "[7,   500] loss: 0.170\n",
      "outputs:  Variable containing:\n",
      " 0.0768  0.0768  0.1065  0.1320  0.0995\n",
      " 0.0737  0.0759  0.1015  0.1275  0.0952\n",
      " 0.0790  0.0777  0.1092  0.1343  0.1014\n",
      " 0.0773  0.0673  0.1001  0.1234  0.0860\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[8,   100] loss: 0.170\n",
      "[8,   200] loss: 0.170\n",
      "[8,   300] loss: 0.170\n",
      "[8,   400] loss: 0.169\n",
      "[8,   500] loss: 0.169\n",
      "outputs:  Variable containing:\n",
      " 0.0845  0.0862  0.1078  0.1389  0.1080\n",
      " 0.0770  0.0903  0.0988  0.1306  0.1038\n",
      " 0.0869  0.0869  0.1103  0.1388  0.1068\n",
      " 0.0843  0.0855  0.1079  0.1359  0.1052\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[9,   100] loss: 0.169\n",
      "[9,   200] loss: 0.168\n",
      "[9,   300] loss: 0.168\n",
      "[9,   400] loss: 0.167\n",
      "[9,   500] loss: 0.168\n",
      "outputs:  Variable containing:\n",
      " 0.0946  0.0901  0.1159  0.1473  0.1158\n",
      " 0.0974  0.0910  0.1211  0.1474  0.1172\n",
      " 0.0922  0.0939  0.1114  0.1439  0.1146\n",
      " 0.0876  0.0987  0.1073  0.1402  0.1162\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n",
      "labels: Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "[10,   100] loss: 0.167\n",
      "[10,   200] loss: 0.167\n",
      "[10,   300] loss: 0.167\n",
      "[10,   400] loss: 0.167\n",
      "[10,   500] loss: 0.166\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs.float()), Variable(labels.float())\n",
    "        if(i == 1):\n",
    "            labelss=labels[:,0]\n",
    "#             print(\"inputs: \", inputs)\n",
    "            print(\"outputs: \", outputs)\n",
    "            print(\"labels:\", labelss)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "#         print('outputs:',outputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "        if(i % 100 == 99):\n",
    "            print('[%d, %5d] loss: %.3[[1. 0.]]f' %\n",
    "                (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outputToTensor(labels):\n",
    "    # print(labels)\n",
    "    # print(labels.numpy().astype(int))\n",
    "    tmp = labels.numpy().astype(int)\n",
    "    # print([ np.where(r==1)[0][0] for r in tmp ])\n",
    "    tmp = [ np.where(r==1)[0][0] for r in tmp ]\n",
    "    tmp = np.array(tmp)\n",
    "    tmp = torch.from_numpy(tmp)\n",
    "    # print(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     0     0     1\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     1     0     0     0     0     0     0     0\n",
      "[torch.DoubleTensor of size 4x10]\n",
      "\n",
      "GroundTruth:   Tan   Mum   Tan  Book\n",
      "outputs: Variable containing:\n",
      "-0.0790 -0.0196  0.3560  0.4597  0.0458 -0.0823  0.1725  0.2134 -0.0267 -0.0705\n",
      " 0.1431  0.0125  0.0211  0.0604 -0.0033 -0.0352 -0.0003  0.0957  0.2255  0.4799\n",
      "-0.0761 -0.0170  0.2782  0.3745  0.0427 -0.0733  0.1284  0.2982  0.0667 -0.0408\n",
      " 0.5559  0.0796  0.0879  0.0069 -0.0152  0.1711  0.0655  0.0926 -0.0749 -0.0059\n",
      "[torch.FloatTensor of size 4x10]\n",
      "\n",
      "\n",
      " 3\n",
      " 9\n",
      " 3\n",
      " 0\n",
      "[torch.LongTensor of size 4]\n",
      "\n",
      "Predicted : Thipok   Mum Thipok  Bone\n"
     ]
    }
   ],
   "source": [
    "dataiter  = iter(testloader)\n",
    "landmarks,labels = dataiter.next()\n",
    "print(labels)\n",
    "tmp = outputToTensor(labels)\n",
    "print('GroundTruth:' ,' '.join('%5s'% classes[int(tmp[j])] for j in range(4)))\n",
    "\n",
    "outputs = net(Variable(landmarks.float()))\n",
    "print('outputs:',outputs)\n",
    "_,predicted = torch.max(outputs.data, 1)\n",
    "print(predicted)\n",
    "print('Predicted :',' '.join('%5s'% classes[int(predicted[j])] for j in range(4) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 70.39999999999999\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "i = 0\n",
    "for data in testloader:\n",
    "    i += 1\n",
    "    images,labels = data\n",
    "    outputs = net(Variable(images.float()))\n",
    "#     if( i < 5): \n",
    "#         print(labels)\n",
    "#         print('output:',torch.max(outputs.data,1))\n",
    "#     print(outputs)\n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "#     print('predicted: ',predicted)\n",
    "#     print('labels: ',labels)\n",
    "    labels = outputToTensor(labels)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()    \n",
    "print('Accuracy :',(correct/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (fc1): Linear (136 -> 136)\n",
      "  (fc2): Linear (136 -> 64)\n",
      "  (fc3): Linear (64 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: secondTry\n"
     ]
    }
   ],
   "source": [
    "name = input('name: ')\n",
    "torch.save(net.state_dict(), 'C:\\\\Users\\\\Bone\\\\Desktop\\\\faces\\\\models\\\\'+name)\n",
    "# print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 10 person\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "name = input('name: ')\n",
    "pickle.dump(net,open('C:\\\\Users\\\\Bone\\\\Desktop\\\\faces\\\\models\\\\' + name, 'wb'))\n",
    "print('saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
