{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.insert(0, \"/opt/intel/mkl/lib/intel64\")\n",
    "sys.path.insert(0, \"/usr/local/lib/python3.6/site-packages\")\n",
    "import dlib\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "\n",
    "def dlibFacelandmarkToNumpy(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    " \n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    " \n",
    "    return coords\n",
    " \n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "DATA_AMOUNT = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"P'An\", 'Bone', 'Thipok', 'Mum', 'Joyce', 'Book', 'chairoj', \"P'Ton\", 'Chal', 'Nick', 'models', 'Tan', 'Nut', \"P'Dear\", 'trainingData', 'Gearng', 'Oat']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('faces/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "\n",
    "STORE_LOCATION = 'faces/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/home/thananop/Downloads/opencv/opencv-3.4.0/modules/imgproc/src/color.cpp:11111: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a2548acc68b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideoInput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/thananop/Downloads/opencv/opencv-3.4.0/modules/imgproc/src/color.cpp:11111: error: (-215) scn == 3 || scn == 4 in function cvtColor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "videoInput = cv2.VideoCapture(0)\n",
    "data = np.ndarray((DATA_AMOUNT,68,2), dtype = float)\n",
    "data_count = 0\n",
    "\n",
    "while (data_count < DATA_AMOUNT):\n",
    "    \n",
    "    _,frame = videoInput.read()\n",
    "   \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    rects = detector(gray, 0)\n",
    "    for rect in rects:\n",
    "#         print('found')\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = dlibFacelandmarkToNumpy(shape)\n",
    "        x, y, w, h = cv2.boundingRect(shape)\n",
    "#         print(shape)\n",
    "#         print('x:',x, 'y:', y, 'w:', w,'h:', h)\n",
    "        shape[:,0] -= x\n",
    "        shape[:,1] -= y\n",
    "        shape_x = shape[:,0]\n",
    "        shape_y = shape[:,1]\n",
    "        shape = shape.astype(float)\n",
    "        shape[:,0] = np.divide(shape_x, w)\n",
    "        shape[:,1] = np.divide(shape_y, h)\n",
    "        data[data_count,:,:] = shape\n",
    "        print(int(data_count * 100 / DATA_AMOUNT),end = '\\r')\n",
    "#         print(shape)\n",
    "        data_count += 1\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "videoInput.release()\n",
    "# print(data)\n",
    "name = input(\"Enter name: \")\n",
    "pickle.dump(data,open(STORE_LOCATION + name, 'wb'))\n",
    "print('stored')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of people:10\n",
      "nameBone\n",
      "nameChal\n",
      "nameBook\n",
      "nameGearng\n",
      "nameNick\n",
      "nameNut\n",
      "nameOat\n",
      "nameP'An\n",
      "nameP'Dear\n",
      "nameP'Ton\n",
      "torch.Size([4000, 136])\n",
      "torch.Size([4000, 10])\n",
      "done loading data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def unpickle(file):\n",
    "    with open(file,'rb') as fo:\n",
    "        output = pickle.load(fo, encoding = 'ASCII')\n",
    "    return output\n",
    "n = int(input('amount of people:'))\n",
    "\n",
    "classes = list()\n",
    "\n",
    "TRAINING_AMOUNT = int(n * DATA_AMOUNT * 4 / 5)\n",
    "TEST_AMOUNT = int(n * DATA_AMOUNT * 1 / 5)\n",
    "\n",
    "training_data = np.ndarray((TRAINING_AMOUNT,68*2))\n",
    "training_labels = np.ndarray((TRAINING_AMOUNT,n))\n",
    "\n",
    "test_data = np.ndarray((TEST_AMOUNT,68 * 2))\n",
    "test_labels = np.ndarray((TEST_AMOUNT,n))\n",
    "\n",
    "training_counter = 0\n",
    "test_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range (n):\n",
    "    name = input('name')\n",
    "    classes.append(name)\n",
    "    data = unpickle(STORE_LOCATION + name)\n",
    "    \n",
    "#     print(data)\n",
    "    training_data[training_counter : training_counter + int(DATA_AMOUNT * 4 / 5),:] = data[: int(DATA_AMOUNT * 4 / 5), :, :].reshape(int(DATA_AMOUNT * 4 / 5), 68 * 2)\n",
    "    test_data[test_counter : test_counter + int(DATA_AMOUNT * 1 / 5)] = data[int(DATA_AMOUNT * 4 / 5) :, :, :].reshape(int(DATA_AMOUNT * 1 / 5), 68 * 2)\n",
    "   \n",
    "    training_labels[training_counter :, :] = 0\n",
    "    training_labels[training_counter : training_counter + int(DATA_AMOUNT * 4 / 5),i] = 1\n",
    "    test_labels[test_counter :, :] = 0\n",
    "    test_labels[test_counter : test_counter + int(DATA_AMOUNT * 1 / 5), i] = 1\n",
    "    \n",
    "    training_counter += int(DATA_AMOUNT * 4 / 5)\n",
    "    test_counter += int(DATA_AMOUNT * 1 / 5)\n",
    "training_data = torch.from_numpy(training_data)\n",
    "training_labels = torch.from_numpy(training_labels)\n",
    "# print(training_data[0])\n",
    "# print(training_labels[0])\n",
    "print(training_data.shape)\n",
    "print(training_labels.shape)\n",
    "\n",
    "print('done loading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of people:4\n",
      "nameBone\n",
      "nameChal\n",
      "nameTanawinBook\n",
      "namethipok\n",
      "torch.Size([1600, 136])\n",
      "torch.Size([1600, 1])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# def unpickle(file):\n",
    "#     with open(file,'rb') as fo:\n",
    "#         output = pickle.load(fo, encoding = 'ASCII')\n",
    "#     return output\n",
    "# n = int(input('amount of people:'))\n",
    "\n",
    "# classes = list()\n",
    "\n",
    "# TRAINING_AMOUNT = int(n * DATA_AMOUNT * 4 / 5)\n",
    "# TEST_AMOUNT = int(n * DATA_AMOUNT * 1 / 5)\n",
    "\n",
    "# training_data = np.ndarray((TRAINING_AMOUNT,68*2))\n",
    "# training_labels = np.ndarray((TRAINING_AMOUNT,1))\n",
    "\n",
    "# test_data = np.ndarray((TEST_AMOUNT,68 * 2))\n",
    "# test_labels = np.ndarray((TEST_AMOUNT,1))\n",
    "\n",
    "# training_counter = 0\n",
    "# test_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "# for i in range (n):\n",
    "#     name = input('name')\n",
    "#     classes.append(name)\n",
    "#     data = unpickle(STORE_LOCATION + name)\n",
    "    \n",
    "# #     print(data)\n",
    "#     training_data[training_counter : training_counter + int(DATA_AMOUNT * 4 / 5),:] = data[: int(DATA_AMOUNT * 4 / 5), :, :].reshape(int(DATA_AMOUNT * 4 / 5), 68 * 2)\n",
    "#     test_data[test_counter : test_counter + int(DATA_AMOUNT * 1 / 5)] = data[int(DATA_AMOUNT * 4 / 5) :, :, :].reshape(int(DATA_AMOUNT * 1 / 5), 68 * 2)\n",
    "   \n",
    "#     training_labels[training_counter : training_counter + int(DATA_AMOUNT * 4 / 5)] = i\n",
    "#     test_labels[test_counter : test_counter + int(DATA_AMOUNT * 1 / 5)] = i\n",
    "    \n",
    "#     training_counter += int(DATA_AMOUNT * 4 / 5)\n",
    "#     test_counter += int(DATA_AMOUNT * 1 / 5)\n",
    "# training_data = torch.from_numpy(training_data)\n",
    "# training_labels = torch.from_numpy(training_labels)\n",
    "# # print(training_data[0])\n",
    "# # print(training_labels[0])\n",
    "# print(training_data.shape)\n",
    "# print(training_labels.shape)\n",
    "\n",
    "# # print('done loading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[1199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class landmarksData(Dataset):\n",
    "    def __init__(self, data, labels, classes,transform=None, data_dir=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform=transform\n",
    "        self.classes = classes\n",
    "    def __getitem__(self,index):\n",
    "        single_landmark_labels = self.labels[index]\n",
    "        single_landmarks = self.data[index]\n",
    "        return (single_landmarks,single_landmark_labels)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "training_set = landmarksData(training_data, training_labels, classes)\n",
    "test_set = landmarksData(test_data, test_labels, classes)\n",
    "print(training_set.__len__())\n",
    "print(test_set.__len__())\n",
    "# print(training_set.__getitem__(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(training_data.type)\n",
    "# print(training_labels.type)\n",
    "# training_set = torch.utils.data.TensorDataset(training_data,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landmarks:  \n",
      " 0.0000\n",
      " 0.1061\n",
      " 0.0076\n",
      " 0.2694\n",
      " 0.0228\n",
      " 0.4245\n",
      " 0.0608\n",
      " 0.5714\n",
      " 0.1255\n",
      " 0.7061\n",
      " 0.2091\n",
      " 0.8204\n",
      " 0.3080\n",
      " 0.9102\n",
      " 0.4183\n",
      " 0.9755\n",
      " 0.5361\n",
      " 0.9959\n",
      " 0.6502\n",
      " 0.9714\n",
      " 0.7338\n",
      " 0.8898\n",
      " 0.8175\n",
      " 0.8041\n",
      " 0.8859\n",
      " 0.6857\n",
      " 0.9392\n",
      " 0.5633\n",
      " 0.9734\n",
      " 0.4286\n",
      " 0.9924\n",
      " 0.2939\n",
      " 0.9962\n",
      " 0.1633\n",
      " 0.1407\n",
      " 0.0490\n",
      " 0.2281\n",
      " 0.0041\n",
      " 0.3270\n",
      " 0.0000\n",
      " 0.4259\n",
      " 0.0286\n",
      " 0.5133\n",
      " 0.0776\n",
      " 0.6426\n",
      " 0.0776\n",
      " 0.7224\n",
      " 0.0327\n",
      " 0.8137\n",
      " 0.0082\n",
      " 0.8973\n",
      " 0.0204\n",
      " 0.9544\n",
      " 0.0776\n",
      " 0.5741\n",
      " 0.1918\n",
      " 0.5779\n",
      " 0.2857\n",
      " 0.5817\n",
      " 0.3755\n",
      " 0.5817\n",
      " 0.4694\n",
      " 0.4563\n",
      " 0.5510\n",
      " 0.5133\n",
      " 0.5633\n",
      " 0.5665\n",
      " 0.5755\n",
      " 0.6160\n",
      " 0.5673\n",
      " 0.6654\n",
      " 0.5551\n",
      " 0.2281\n",
      " 0.1837\n",
      " 0.2928\n",
      " 0.1673\n",
      " 0.3612\n",
      " 0.1714\n",
      " 0.4144\n",
      " 0.2204\n",
      " 0.3536\n",
      " 0.2327\n",
      " 0.2852\n",
      " 0.2245\n",
      " 0.6996\n",
      " 0.2245\n",
      " 0.7605\n",
      " 0.1837\n",
      " 0.8251\n",
      " 0.1837\n",
      " 0.8745\n",
      " 0.2082\n",
      " 0.8289\n",
      " 0.2408\n",
      " 0.7605\n",
      " 0.2408\n",
      " 0.3650\n",
      " 0.7102\n",
      " 0.4449\n",
      " 0.6939\n",
      " 0.5095\n",
      " 0.6776\n",
      " 0.5551\n",
      " 0.6939\n",
      " 0.6008\n",
      " 0.6816\n",
      " 0.6578\n",
      " 0.7061\n",
      " 0.7186\n",
      " 0.7265\n",
      " 0.6578\n",
      " 0.7796\n",
      " 0.6008\n",
      " 0.8041\n",
      " 0.5513\n",
      " 0.8122\n",
      " 0.5019\n",
      " 0.8041\n",
      " 0.4373\n",
      " 0.7755\n",
      " 0.3954\n",
      " 0.7184\n",
      " 0.5095\n",
      " 0.7265\n",
      " 0.5551\n",
      " 0.7347\n",
      " 0.6008\n",
      " 0.7306\n",
      " 0.6920\n",
      " 0.7265\n",
      " 0.6008\n",
      " 0.7429\n",
      " 0.5551\n",
      " 0.7469\n",
      " 0.5095\n",
      " 0.7429\n",
      "[torch.DoubleTensor of size 136]\n",
      "\n",
      "label:  \n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainloader = DataLoader(training_set, batch_size=4,shuffle=True)\n",
    "dataiter = iter(trainloader)\n",
    "landmarks, label = dataiter.next()\n",
    "print(\"landmarks: \",landmarks[0])\n",
    "print(\"label: \",label[0])\n",
    "testloader = DataLoader(test_set, batch_size=4,shuffle=True)\n",
    "testiter = iter(testloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "def foo(l, dtype=float):\n",
    "    return map(dtype, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=136, out_features=136)\n",
      "  (fc2): Linear(in_features=136, out_features=64)\n",
      "  (fc3): Linear(in_features=64, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(68 * 2, 68 * 2)\n",
    "        self.fc2 = nn.Linear(68 * 2, 64)\n",
    "        self.fc3 = nn.Linear(64, n)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "# net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion =  nn.MSELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 100 ]  loss:  0.027582438956014813\n",
      "[ 1 200 ]  loss:  0.02814427500590682\n",
      "[ 1 300 ]  loss:  0.026836001691408456\n",
      "[ 1 400 ]  loss:  0.025255680081900208\n",
      "[ 1 500 ]  loss:  0.027505785031244158\n",
      "[ 1 600 ]  loss:  0.026155354068614543\n",
      "[ 1 700 ]  loss:  0.026871621822938323\n",
      "[ 1 800 ]  loss:  0.026790271000936627\n",
      "[ 1 900 ]  loss:  0.026946685216389595\n",
      "[ 1 1000 ]  loss:  0.024446669365279377\n",
      "[ 2 100 ]  loss:  0.024247564151883127\n",
      "[ 2 200 ]  loss:  0.026712465984746813\n",
      "[ 2 300 ]  loss:  0.024684615111909808\n",
      "[ 2 400 ]  loss:  0.026626556566916405\n",
      "[ 2 500 ]  loss:  0.025314008013810962\n",
      "[ 2 600 ]  loss:  0.02676909974310547\n",
      "[ 2 700 ]  loss:  0.026071020355448126\n",
      "[ 2 800 ]  loss:  0.026258331175195052\n",
      "[ 2 900 ]  loss:  0.027338962368667126\n",
      "[ 2 1000 ]  loss:  0.027675393261015414\n",
      "[ 3 100 ]  loss:  0.02535041977185756\n",
      "[ 3 200 ]  loss:  0.025008138874545692\n",
      "[ 3 300 ]  loss:  0.02481859066989273\n",
      "[ 3 400 ]  loss:  0.028119607996195554\n",
      "[ 3 500 ]  loss:  0.025903044855222105\n",
      "[ 3 600 ]  loss:  0.02669770162552595\n",
      "[ 3 700 ]  loss:  0.026733028604649007\n",
      "[ 3 800 ]  loss:  0.0247308611869812\n",
      "[ 3 900 ]  loss:  0.02486594408284873\n",
      "[ 3 1000 ]  loss:  0.026080746478401126\n",
      "[ 4 100 ]  loss:  0.027751393844373525\n",
      "[ 4 200 ]  loss:  0.02533171363873407\n",
      "[ 4 300 ]  loss:  0.023338746279478073\n",
      "[ 4 400 ]  loss:  0.024796745497733353\n",
      "[ 4 500 ]  loss:  0.023461586851626633\n",
      "[ 4 600 ]  loss:  0.025383179592899978\n",
      "[ 4 700 ]  loss:  0.026175658297725023\n",
      "[ 4 800 ]  loss:  0.02650988332461566\n",
      "[ 4 900 ]  loss:  0.024338102843612434\n",
      "[ 4 1000 ]  loss:  0.02815656126011163\n",
      "[ 5 100 ]  loss:  0.025626419796608388\n",
      "[ 5 200 ]  loss:  0.02231856470927596\n",
      "[ 5 300 ]  loss:  0.02424236201681197\n",
      "[ 5 400 ]  loss:  0.025161594566889108\n",
      "[ 5 500 ]  loss:  0.026652234913781284\n",
      "[ 5 600 ]  loss:  0.025077927361708136\n",
      "[ 5 700 ]  loss:  0.025428416482172908\n",
      "[ 5 800 ]  loss:  0.025466117546893655\n",
      "[ 5 900 ]  loss:  0.026003703521564604\n",
      "[ 5 1000 ]  loss:  0.026177449126262218\n",
      "[ 6 100 ]  loss:  0.02484410970006138\n",
      "[ 6 200 ]  loss:  0.026802568957209588\n",
      "[ 6 300 ]  loss:  0.024412804269231855\n",
      "[ 6 400 ]  loss:  0.024392602001316845\n",
      "[ 6 500 ]  loss:  0.025799973118118942\n",
      "[ 6 600 ]  loss:  0.023242946604732424\n",
      "[ 6 700 ]  loss:  0.02319767138455063\n",
      "[ 6 800 ]  loss:  0.025738976409193128\n",
      "[ 6 900 ]  loss:  0.025331375570967794\n",
      "[ 6 1000 ]  loss:  0.026172521584667267\n",
      "[ 7 100 ]  loss:  0.025606990437954665\n",
      "[ 7 200 ]  loss:  0.02417503545060754\n",
      "[ 7 300 ]  loss:  0.023780558588914574\n",
      "[ 7 400 ]  loss:  0.024407833807636052\n",
      "[ 7 500 ]  loss:  0.023454759335145355\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs.float()), Variable(labels.float())\n",
    "#         if(i == 1):\n",
    "#             labelss=labels[:,0]\n",
    "#             print(\"inputs: \", inputs)\n",
    "#             print(\"outputs: \", outputs)\n",
    "#             print(\"labels:\", labelss)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "#         print('outputs:',outputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "        if(i % 100 == 99):\n",
    "            print('[',epoch + 1,i + 1,']', ' loss: ',running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outputToTensor(labels):\n",
    "    # print(labels)\n",
    "    # print(labels.numpy().astype(int))\n",
    "    tmp = labels.numpy().astype(int)\n",
    "    # print([ np.where(r==1)[0][0] for r in tmp ])\n",
    "    tmp = [ np.where(r==1)[0][0] for r in tmp ]\n",
    "    tmp = np.array(tmp)\n",
    "    tmp = torch.from_numpy(tmp)\n",
    "    # print(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     0     0     1\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     1     0     0     0     0     0     0     0\n",
      "[torch.DoubleTensor of size 4x10]\n",
      "\n",
      "GroundTruth:   Tan   Mum   Tan  Book\n",
      "outputs: Variable containing:\n",
      "-0.0790 -0.0196  0.3560  0.4597  0.0458 -0.0823  0.1725  0.2134 -0.0267 -0.0705\n",
      " 0.1431  0.0125  0.0211  0.0604 -0.0033 -0.0352 -0.0003  0.0957  0.2255  0.4799\n",
      "-0.0761 -0.0170  0.2782  0.3745  0.0427 -0.0733  0.1284  0.2982  0.0667 -0.0408\n",
      " 0.5559  0.0796  0.0879  0.0069 -0.0152  0.1711  0.0655  0.0926 -0.0749 -0.0059\n",
      "[torch.FloatTensor of size 4x10]\n",
      "\n",
      "\n",
      " 3\n",
      " 9\n",
      " 3\n",
      " 0\n",
      "[torch.LongTensor of size 4]\n",
      "\n",
      "Predicted : Thipok   Mum Thipok  Bone\n"
     ]
    }
   ],
   "source": [
    "dataiter  = iter(testloader)\n",
    "landmarks,labels = dataiter.next()\n",
    "print(labels)\n",
    "tmp = outputToTensor(labels)\n",
    "print('GroundTruth:' ,' '.join('%5s'% classes[int(tmp[j])] for j in range(4)))\n",
    "\n",
    "outputs = net(Variable(landmarks.float()))\n",
    "print('outputs:',outputs)\n",
    "_,predicted = torch.max(outputs.data, 1)\n",
    "print(predicted)\n",
    "print('Predicted :',' '.join('%5s'% classes[int(predicted[j])] for j in range(4) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 70.39999999999999\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "i = 0\n",
    "for data in testloader:\n",
    "    i += 1\n",
    "    images,labels = data\n",
    "    outputs = net(Variable(images.float()))\n",
    "#     if( i < 5): \n",
    "#         print(labels)\n",
    "#         print('output:',torch.max(outputs.data,1))\n",
    "#     print(outputs)\n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "#     print('predicted: ',predicted)\n",
    "#     print('labels: ',labels)\n",
    "    labels = outputToTensor(labels)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()    \n",
    "print('Accuracy :',(correct/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (fc1): Linear (136 -> 136)\n",
      "  (fc2): Linear (136 -> 64)\n",
      "  (fc3): Linear (64 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: secondTry\n"
     ]
    }
   ],
   "source": [
    "name = input('name: ')\n",
    "torch.save(net.state_dict(), 'C:\\\\Users\\\\Bone\\\\Desktop\\\\faces\\\\models\\\\'+name)\n",
    "# print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 10 person\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "name = input('name: ')\n",
    "pickle.dump(net,open('C:\\\\Users\\\\Bone\\\\Desktop\\\\faces\\\\models\\\\' + name, 'wb'))\n",
    "print('saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
